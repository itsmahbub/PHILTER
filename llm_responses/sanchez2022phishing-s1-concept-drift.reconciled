{"value":"Medium","why":"The paper rigorously evaluates phishing detection over temporally disjoint datasets—training on 2016 URLs and testing on 2017 and 2020 URLs—to quantify performance degradation (concept drift). However, it does not implement or empirically validate any adaptive strategy (e.g., continual learning, periodic retraining, or time-aware feature design) to mitigate drift—it only recommends retraining on recent data. Thus, it meets the Medium criteria: temporal evaluation without an implemented adaptive approach.","evidence":"Page 3, Contributions: “We evaluated the robustness of the proposed phishing detection over time. We trained the model on a dataset collected between March 2016 and April 2016, and we evaluated the model on other datasets collected between 2017 and 2020.”; Page 9, Section VI.B: “From the experimental results shown in Table 7, all models struggled to endure over time and their performance decreased when tested on the following years’ datasets.”"}