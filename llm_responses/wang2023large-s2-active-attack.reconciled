{"value":"Medium","why":"PhishBERT incorporates explicit defenses against URL‐level manipulations within its input modality through (1) a Manipulated Token Detection (MTD) pre‐training objective that trains the model to recognize randomly replaced or shuffled tokens, and (2) a smoothness inductive adversarial regularization during fine‐tuning to improve robustness against adversarial perturbations. However, the paper does not provide an evaluation on an adversarial or evasion‐focused dataset, nor does it present a quantitative breakdown of specific attack types in its experiments, precluding a “High” rating.","evidence":"Page 2, Section 2.4 (Pre‐training Objectives): “The MTD randomly replaces or shuffles tokens in a sequence… and its goal is to predict whether a token … has been manipulated.”\nPage 2, Section 2.5 (Fine‐tuning PhishBERT): “We apply… smoothness inductive adversarial regularization… strengthening the stationarity of the model.”\nPage 4, Section 4 (Numerical Evaluation): experiments use standard metrics (accuracy, F1, TPR@FPR) on random splits without any adversarial or evasion‐focused dataset or quantitative attack analysis."}