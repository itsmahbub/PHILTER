```json
{
    "value": "Medium",
    "why": "The proposed method does not incorporate any explicit adaptive mechanisms like periodic retraining or online learning to handle concept drift. The models (CNN-LSTM, XGBoost) are trained statically. However, the evaluation protocol includes an experiment that simulates a temporal split, which is a key requirement for assessing resilience to concept drift. The authors train their CNN-LSTM model on a large historical dataset of phishing URLs collected from 2014-2018 (DATA2) and then test its performance on a dataset composed of currently live and accessible phishing URLs (DATA1). They observe a performance degradation in this scenario and explicitly acknowledge that this is due to concept drift, stating that \"Phishing website URLs have different characteristics in different periods\". This evaluation on data from a different temporal context satisfies one of the main criteria for a rating higher than 'Low'.",
    "evidence": "Page 11, right column: \"However, the effect is worse than the 5-fold cross-validation of the CNN-LSTM algorithm on DATA2, as shown in Table 4, because the samples in DATA1 are currently accessible URLs, whereas the phishing website URLs in DATA2 are historical data and currently inaccessible. Phishing website URLs have different characteristics in different periods due to the different target websites they imitate. Note that the CNN-LSTM model used in the following experiments is trained with DATA2.\"\n\nPage 9, Section V-A: \"First, historical data confirmed as phishing from 2014 to 2018 were crawled from the PhishTank website, and a total of 1 021 758 URLs were used as positive samples of the phishing... To solve this problem, we build the dataset DATA1 by extracting the currently surviving 22 445 URLs as phishing from DATA positive samples... The remaining data in DATA are built into the dataset DATA2...\""
}
```