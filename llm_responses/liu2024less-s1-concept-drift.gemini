```json
{
    "value": "High",
    "why": "The proposed method, PhishLLM, is inherently designed to be robust against concept drift. It avoids volatile, easily changed features (like URL structure or HTML source) by focusing on the more stable semantic and visual aspects of brand identity and credential-taking intention. By leveraging a Large Language Model (LLM) as its knowledge base, it implicitly adapts to new brands and linguistic patterns without needing an explicit, manually maintained reference list, which is a major source of staleness in traditional reference-based detectors. Crucially, the evaluation methodology strongly supports this claim. The paper includes a 30-day large-scale field study where PhishLLM is deployed against newly emerging websites from CertStream feeds. This constitutes a time-forward evaluation, testing the model's ability to detect zero-day attacks and handle evolving phishing tactics in the wild, which directly addresses the core requirement of the metric.",
    "evidence": "Page 8, Section 4.1.3, \"Field Study Evaluation: CertStream Service. We crawl websites from Certstream feeds, which offer domains with newly issued or updated TLS certificates. We crawled 3,000 emerging websites daily from CertStream [1], and the crawling lasted for 30 days, yielding a total of 90,000 websites.\"\n\nPage 2, Abstract, \"In this work, we present PhishLLM as a novel reference-based phishing detector that operates without an explicit pre-defined reference list. Our rationale lies in that modern LLMs have encoded far more extensive brand-domain information than any predefined list.\"\n\nPage 11, Section 4.5.2, \"Table 7 shows the results of a large-scale field study, indicating that PhishLLM significantly outperforms the baselines, reporting far more real-world phishing websites (1,340 compared to 178 and 107). The advantage lies in that PhishLLM can infer phishing websites by decoding far more references.\""
}
```