{"value":"Low","why":"The AdaptPUD method is presented as a purely black‐box deep learning approach (token‐property embeddings, multi‐channel CNN, BiGRU, self‐attention and fastKAN) with no accompanying mechanism for per‐instance or global explanation of its predictions. The paper does not propose or discuss any Explainable AI techniques (e.g., SHAP, LIME, heatmaps) nor expose the model’s decision path or feature importances for auditing or interpretability.","evidence":"Pages 4–6, Sections 4.2–4.3: The paper details embedding and model architecture (multi‐channel feature extraction, BiGRU, self‐attention, fastKAN) and a concept drift detector, but contains no mention of interpretability, post hoc explanations, feature importance analysis, or any method to explain individual classification decisions."}